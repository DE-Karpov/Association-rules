{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comaru.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DE-Karpov/comaru/blob/develop/comaru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Tw1t8feLeV"
      },
      "source": [
        "!pip install apyori\n",
        "\n",
        "!pip install pyfpgrowth\n",
        "\n",
        "!pip install mlxtend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFOju6zmrc3k"
      },
      "source": [
        "from apyori import apriori\n",
        "from google.colab import files\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori as mapriori, fpgrowth, fpmax\n",
        "import pyfpgrowth\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPbN_fTPsFNd"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCFjFGqCrqce"
      },
      "source": [
        "class AssocRules:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.dataset = pd.read_csv(\"retail_dataset.csv\")\n",
        "        self.transactions = []\n",
        "        self.fill_transactions()\n",
        "\n",
        "    def fill_transactions(self):\n",
        "        for i in range(0, 315): \n",
        "            self.transactions.append([str(self.dataset.values[i,j]) for j in range(0, 6) if not pd.isnull(self.dataset.values[i,j])])    \n",
        "\n",
        "    class Eclat:\n",
        "\n",
        "        def __init__(self, min_support = 0.01, max_items = 5, min_items = 2):\n",
        "            self.min_support = min_support\n",
        "            self.max_items = max_items\n",
        "            self.min_items = min_items\n",
        "            self.item_lst = list()\n",
        "            self.item_len = 0\n",
        "            self.item_dict = dict()\n",
        "            self.final_dict = dict()\n",
        "            self.data_size = 0\n",
        "        \n",
        "        def read_data(self, dataset):\n",
        "            for index, row in dataset.iterrows():\n",
        "                row_wo_na = set(row)\n",
        "                for item in row_wo_na:\n",
        "                    if pd.isnull(item):\n",
        "                        continue\n",
        "                    else:\n",
        "                        item = item.strip()\n",
        "                    if item in self.item_dict:\n",
        "                        self.item_dict[item][0] += 1\n",
        "                    else:\n",
        "                        self.item_dict.setdefault(item, []).append(1)\n",
        "                    self.item_dict[item].append(index)\n",
        "\n",
        "            self.data_size = dataset.shape[0]\n",
        "            self.item_lst = list(self.item_dict.keys())\n",
        "            self.item_len = len(self.item_lst)\n",
        "            self.min_support = self.min_support * self.data_size\n",
        "            \n",
        "        def recur_eclat(self, item_name, tids_array, minsupp, num_items, k_start):\n",
        "            if tids_array[0] >= minsupp and num_items <= self.max_items:\n",
        "                for k in range(k_start+1, self.item_len):\n",
        "                    if self.item_dict[self.item_lst[k]][0] >= minsupp:\n",
        "                        new_item = item_name + \"|\" + self.item_lst[k]\n",
        "                        new_tids = np.intersect1d(tids_array[1:], self.item_dict[self.item_lst[k]][1:])\n",
        "                        new_tids_size = new_tids.size\n",
        "                        new_tids = np.insert(new_tids, 0, new_tids_size)\n",
        "                        if new_tids_size >= minsupp:\n",
        "                            if num_items >= self.min_items: self.final_dict.update({new_item: new_tids})\n",
        "                            self.recur_eclat(new_item, new_tids, minsupp, num_items+1, k)\n",
        "        \n",
        "        def fit(self, dataset):\n",
        "            i = 0\n",
        "            self.read_data(dataset)\n",
        "            for w in self.item_lst:\n",
        "                self.recur_eclat(w, self.item_dict[w], self.min_support, 2, i)\n",
        "                i+=1\n",
        "            return self\n",
        "            \n",
        "        def transform(self):\n",
        "            return [k[0].split(\"|\") for k in self.final_dict.items()]\n",
        "\n",
        "\n",
        "    def get_apriori(self, params):\n",
        "      rules = list(apriori(self.transactions, min_support = params[\"min_support\"], min_confidence = params[\"min_confidence\"], min_lift = params[\"min_lift\"], max_length = params[\"max_length\"]))\n",
        "      list_of_rules = [list(record.items) for record in rules]\n",
        "      return list_of_rules\n",
        "\n",
        "    def get_eclat(self, params):\n",
        "      model = AssocRules.Eclat(min_support = params[\"min_support\"], max_items = params[\"max_length\"], min_items = 1)\n",
        "      model.fit(self.dataset)\n",
        "      return model.transform()\n",
        "\n",
        "    def get_fpgrowth(self, params):\n",
        "      support_threshold = int(len(self.transactions) * params['min_support'])\n",
        "      patterns = pyfpgrowth.find_frequent_patterns(self.transactions, support_threshold)\n",
        "      new_patterns = {k: v for k, v in patterns.items() if not ((\"nan\") in k)}\n",
        "      unprepared_list = list(pyfpgrowth.generate_association_rules(new_patterns, params[\"min_confidence\"]))\n",
        "      prepared_list = [list(item) for item in unprepared_list if len(item) == 2 ]\n",
        "      return prepared_list\n",
        "\n",
        "    def user_input_features(self):\n",
        "      min_support = st.sidebar.slider(\"Minimal support\", 0.01, 0.03, 0.001)\n",
        "      min_confidence = st.sidebar.slider(\"Min confidence\", 0.2, 0.6, 0.1)\n",
        "      min_lift = st.sidebar.slider(\"Lift\", 0.5, 6.0, 1.0)\n",
        "      min_length = st.sidebar.slider(\"Min length\", 1, 2, 3)\n",
        "      data = {\"min_support\": min_support,\n",
        "              \"min_confidence\": min_confidence,\n",
        "              \"min_lift\": min_lift,\n",
        "              \"min_length\": min_length}\n",
        "      features = pd.DataFrame(data, index=[0])\n",
        "      return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0buZAP5-VQ-"
      },
      "source": [
        "rules = AssocRules()\n",
        "\n",
        "confidence = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "\n",
        "def gen_rules(min_support, min_lift = 2.0, max_length = None, alg = 'apriori'):\n",
        "    ap = {}\n",
        "    common_rules = []\n",
        "    if alg == 'apriori':\n",
        "      for i in confidence:\n",
        "        parameters = {\"min_support\" : min_support, \"min_confidence\" : i, \"min_lift\" : min_lift, \"max_length\" : max_length}\n",
        "        apriori_rules = rules.get_apriori(parameters)\n",
        "        ap[i] = len(apriori_rules)\n",
        "        common_rules.append(apriori_rules)\n",
        "    elif alg == 'fpgrowth':\n",
        "      for i in confidence:\n",
        "        parameters = {\"min_support\" : min_support, \"min_confidence\" : i}\n",
        "        fpgrowth_rules = rules.get_fpgrowth(parameters)\n",
        "        ap[i] = len(fpgrowth_rules)\n",
        "        common_rules.append(fpgrowth_rules)\n",
        "    return pd.Series(ap).to_frame(\"Support: %s\"%min_support), common_rules\n",
        "\n",
        "apriori_plot = []\n",
        "fpgrowth_plot = []\n",
        "common_rules_plot = []\n",
        "for i in [0.005,0.01,0.05,0.1]:\n",
        "    apriori_alg = gen_rules(min_support = i)\n",
        "    fpgrowth_alg = gen_rules(min_support = i, alg='fpgrowth')\n",
        "    apriori_plot.append(apriori_alg[0])\n",
        "    fpgrowth_plot.append(fpgrowth_alg[0])\n",
        "\n",
        "apriori_all_conf = pd.concat(apriori_plot, axis=1)\n",
        "fpgrowth_all_conf = pd.concat(fpgrowth_plot, axis=1)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (16, 8))\n",
        "fig.suptitle('Association rules')\n",
        "ax1.set_title('Apriori')\n",
        "ax2.set_title('FPGrowth')\n",
        "ax1.plot(apriori_all_conf)\n",
        "ax2.plot(fpgrowth_all_conf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfSSyDLNTc8w"
      },
      "source": [
        "def getCommonRules(leftRules, rightRules):\n",
        "  commonRules = []\n",
        "  print(rightRules)\n",
        "  for leftSubList in leftRules:\n",
        "    for rightSubList in rightRules:\n",
        "      if leftSubList == rightRules:\n",
        "        commonRules.append(rightRules)\n",
        "  return commonRules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPiN50B5YCLS"
      },
      "source": [
        "def createOneHotVec(df):\n",
        "  items = (df['0'].unique())\n",
        "  itemset = set(items)\n",
        "  encoded_vals = []\n",
        "  for index, row in df.iterrows():\n",
        "      rowset = set(row) \n",
        "      labels = {}\n",
        "      uncommons = list(itemset - rowset)\n",
        "      commons = list(itemset.intersection(rowset))\n",
        "      for uc in uncommons:\n",
        "          labels[uc] = 0\n",
        "      for com in commons:\n",
        "          labels[com] = 1\n",
        "      encoded_vals.append(labels)\n",
        "  encoded_vals[0]\n",
        "  ohe_df = pd.DataFrame(encoded_vals)\n",
        "  return ohe_df"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Mz5GALYCcy"
      },
      "source": [
        "def getAprioriRules(df):\n",
        "  ohe_df = createOneHotVec(df)\n",
        "  freq_items = mapriori(ohe_df, min_support=0.2, use_colnames=True, verbose=1)\n",
        "  assoc_rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.2)\n",
        "  return assoc_rules"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHK7rEYqcgCW"
      },
      "source": [
        "def getFPGrowthRules(df):\n",
        "  ohe_df = createOneHotVec(df)\n",
        "  freq_items = fpgrowth(ohe_df, min_support=0.2, use_colnames=True, verbose=1)\n",
        "  assoc_rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.2)\n",
        "  return assoc_rules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXpC8jLicgPd"
      },
      "source": [
        "def getFPMaxRules(df):\n",
        "  ohe_df = createOneHotVec(df)\n",
        "  freq_items = fpmax(ohe_df, min_support=0.2, use_colnames=True, verbose=1)\n",
        "  assoc_rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.2, support_only=True)\n",
        "  return assoc_rules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ySWloWlgPA5"
      },
      "source": [
        "new_rules = rules.dataset"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOlNbw5DhTBj",
        "outputId": "68f4eab9-1b58-499e-95eb-6948b0e05b5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t0= time.clock()\n",
        "getAprioriRules(new_rules).head()\n",
        "t1 = time.clock() - t0\n",
        "print(\"Apriori time: \", t1) # CPU seconds elapsed (floating point)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rProcessing 72 combinations | Sampling itemset size 2\rProcessing 189 combinations | Sampling itemset size 3\n",
            "Apriori time:  0.04781200000000041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkQkz3ERhiV1",
        "outputId": "c04c4477-a74f-4268-963c-a50f7962a339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t0= time.clock()\n",
        "getFPGrowthRules(new_rules).head()\n",
        "t1 = time.clock() - t0\n",
        "print(\"FPGrowth time: \", t1) # CPU seconds elapsed (floating point)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r9 itemset(s) from tree conditioned on items ()\n",
            "\r0 itemset(s) from tree conditioned on items (Bread)\n",
            "\r1 itemset(s) from tree conditioned on items (Cheese)\n",
            "\r3 itemset(s) from tree conditioned on items (Meat)\n",
            "\r0 itemset(s) from tree conditioned on items (Meat, Cheese)\n",
            "\r0 itemset(s) from tree conditioned on items (Meat, Bread)\n",
            "\r1 itemset(s) from tree conditioned on items (Meat, Milk)\n",
            "\r3 itemset(s) from tree conditioned on items (Eggs)\n",
            "\r0 itemset(s) from tree conditioned on items (Eggs, Cheese)\n",
            "\r1 itemset(s) from tree conditioned on items (Eggs, Meat)\n",
            "\r0 itemset(s) from tree conditioned on items (Eggs, Milk)\n",
            "\r5 itemset(s) from tree conditioned on items (Wine)\n",
            "\r0 itemset(s) from tree conditioned on items (Wine, Cheese)\n",
            "\r0 itemset(s) from tree conditioned on items (Wine, Meat)\n",
            "\r0 itemset(s) from tree conditioned on items (Wine, Bread)\n",
            "\r0 itemset(s) from tree conditioned on items (Wine, Eggs)\n",
            "\r0 itemset(s) from tree conditioned on items (Wine, Milk)\n",
            "\r3 itemset(s) from tree conditioned on items (Diaper)\n",
            "\r0 itemset(s) from tree conditioned on items (Diaper, Wine)\n",
            "\r0 itemset(s) from tree conditioned on items (Diaper, Bread)\n",
            "\r0 itemset(s) from tree conditioned on items (Diaper, Cheese)\n",
            "\r3 itemset(s) from tree conditioned on items (Pencil)\n",
            "\r0 itemset(s) from tree conditioned on items (Pencil, Wine)\n",
            "\r0 itemset(s) from tree conditioned on items (Pencil, Cheese)\n",
            "\r0 itemset(s) from tree conditioned on items (Pencil, Bread)\n",
            "\r2 itemset(s) from tree conditioned on items (Milk)\n",
            "\r0 itemset(s) from tree conditioned on items (Milk, Cheese)\n",
            "\r0 itemset(s) from tree conditioned on items (Milk, Bread)\n",
            "\r2 itemset(s) from tree conditioned on items (Bagel)\n",
            "\r0 itemset(s) from tree conditioned on items (Bagel, Bread)\n",
            "\r0 itemset(s) from tree conditioned on items (Bagel, Milk)\n",
            "FPGrowth time:  0.05696700000000021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg8yGXIihijO",
        "outputId": "45ff2d4e-a4e8-4fca-e263-35425e7c9300",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t0= time.clock()\n",
        "getFPMaxRules(new_rules).head()\n",
        "t1 = time.clock() - t0\n",
        "print(\"FPMax time: \", t1) # CPU seconds elapsed (floating point)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0 itemset(s) from tree conditioned on items ()\n",
            "\r0 itemset(s) from tree conditioned on items (Pencil)\n",
            "\r1 itemset(s) from tree conditioned on items (Pencil, Bread)\n",
            "\r1 itemset(s) from tree conditioned on items (Pencil, Cheese)\n",
            "\r1 itemset(s) from tree conditioned on items (Pencil, Wine)\n",
            "\r0 itemset(s) from tree conditioned on items (Diaper)\n",
            "\r1 itemset(s) from tree conditioned on items (Diaper, Cheese)\n",
            "\r1 itemset(s) from tree conditioned on items (Diaper, Bread)\n",
            "\r1 itemset(s) from tree conditioned on items (Diaper, Wine)\n",
            "\r0 itemset(s) from tree conditioned on items (Bagel)\n",
            "\r1 itemset(s) from tree conditioned on items (Bagel, Milk)\n",
            "\r1 itemset(s) from tree conditioned on items (Bagel, Bread)\n",
            "\r0 itemset(s) from tree conditioned on items (Wine)\n",
            "\r1 itemset(s) from tree conditioned on items (Wine, Milk)\n",
            "\r1 itemset(s) from tree conditioned on items (Wine, Eggs)\n",
            "\r1 itemset(s) from tree conditioned on items (Wine, Bread)\n",
            "\r1 itemset(s) from tree conditioned on items (Wine, Meat)\n",
            "\r1 itemset(s) from tree conditioned on items (Wine, Cheese)\n",
            "\r0 itemset(s) from tree conditioned on items (Eggs)\n",
            "\r1 itemset(s) from tree conditioned on items (Eggs, Milk)\n",
            "\r1 itemset(s) from tree conditioned on items (Eggs, Meat)\n",
            "\r0 itemset(s) from tree conditioned on items (Meat)\n",
            "\r1 itemset(s) from tree conditioned on items (Meat, Bread)\n",
            "\r1 itemset(s) from tree conditioned on items (Meat, Milk)\n",
            "\r0 itemset(s) from tree conditioned on items (Milk)\n",
            "\r1 itemset(s) from tree conditioned on items (Milk, Bread)\n",
            "\r1 itemset(s) from tree conditioned on items (Cheese)\n",
            "FPMax time:  0.054658000000003426\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}